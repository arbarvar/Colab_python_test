{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scraping.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN0orsYupDrB4J6iDVibBlX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arbarvar/Colab_python_test/blob/main/Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smmfjJA_WqD8"
      },
      "source": [
        "#Web scraping in Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqfQGTJMW0K5"
      },
      "source": [
        "#Install requirment packages\n",
        "#!pip install requests\n",
        "#!pip install beautifulsoup4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhie0guGXKtP"
      },
      "source": [
        "#Import Moduls\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import lxml.etree as xml\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W58bC021g945",
        "outputId": "a2b30f3c-8bff-434a-9b41-caf468f4d83b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# IMDB's homepage\n",
        "imdb_url = 'https://www.imdb.com'\n",
        "\n",
        "# Use requests to retrieve data from a given URL\n",
        "imdb_response = requests.get(imdb_url)\n",
        "\n",
        "# Fake the user agent so the web page thinks we access it as a regular human user\n",
        "#imdb_response = requests.get(imdb_url,headers={\n",
        "#    \"UserAgent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.183 Safari/537.36\"\n",
        "#}).text, \"lxml\")\n",
        "\n",
        "# Parse the whole HTML page using BeautifulSoup\n",
        "imdb_soup = BeautifulSoup(imdb_response.text, 'html.parser')\n",
        "\n",
        "# Title of the parsed page\n",
        "imdb_soup.title"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<title data-react-helmet=\"true\">IMDb: Ratings, Reviews, and Where to Watch the Best Movies &amp; TV Shows</title>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQOo08Y-iCA6"
      },
      "source": [
        "# We can also get it without the HTML tags\n",
        "imdb_soup.title.string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjMu20R-iPYf"
      },
      "source": [
        "# Collect trailers' title and description\n",
        "trailers = imdb_soup.find('div', {'class': 'ab_hero'})\n",
        "#print(trailers.prettify())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TqpQFg2i2g4"
      },
      "source": [
        "#We will use the .find_all() method to search the HTML tree for particular tags and get a list with all the relevant objects.\n",
        "for title, image in zip(trailers.find_all('div', {'class': 'onoverflow'}), trailers.find_all('img', {'class': 'pri_image'})):\n",
        "    print(f\"{title.text}: {image['title']}\")\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWe-looskVgg"
      },
      "source": [
        "# Collect Side Bar\n",
        "for widget in imdb_soup.find_all('div', {'class': 'aux-content-widget-2'}):\n",
        "    # Check that the widget has a heading\n",
        "    if widget.h3:\n",
        "        # Print the widget's heading along with the movie titles.\n",
        "        print(widget.h3.string)\n",
        "        for title in widget.find_all('div', {'class': 'title'}):\n",
        "            print(title.text)\n",
        "        print()"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}